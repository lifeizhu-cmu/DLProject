# -*- coding: utf-8 -*-
"""IDL-Protect.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xgo90QXQo_7fZ1xzwyBQOcSidKO6S8ff
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/

!mkdir ~/.kaggle
!cp /content/kaggle.json ~/.kaggle

!kaggle datasets download -d zaraks/pascal-voc-2007

from zipfile import ZipFile
file_name = "pascal-voc-2007.zip"
with ZipFile(file_name,'r') as zipObj:
  zipObj.extractall()

import os
import numpy as np
from PIL import Image

import torch
import torchvision   
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
import sklearn.metrics
import pandas as pd

is_cuda = torch.cuda.is_available()
if is_cuda:
    device = torch.device("cuda")
    print("GPU is available")
else:
    device = torch.device("cpu")
    print("GPU not available, CPU used")

class ImageDataset(Dataset):
    def __init__(self, file_list1, file_list2):
        self.image_list = file_list1
        self.label_list = torch.LongTensor(file_list2)

    def __len__(self):
        return len(self.image_list)

    def __getitem__(self, index):
        img = Image.open("/content/voctrainval_06-nov-2007/VOCdevkit/VOC2007/JPEGImages/"+
                         self.image_list[index]+".jpg")
        img = img.resize((224,224))
        img = torchvision.transforms.ToTensor()(img)
        label = self.label_list[index] + 1
        
        return img, label

train_txt = np.loadtxt('/content/voctrainval_06-nov-2007/VOCdevkit/VOC2007/ImageSets/Main/car_train.txt',dtype=bytes).astype(str)
train_img = train_txt[:,0]
train_label = train_txt[:,1].astype(int)
train_set = ImageDataset(train_img, train_label)
train_dataloader = DataLoader(train_set , batch_size=10, shuffle=True, num_workers=8)

val_txt = np.loadtxt('/content/voctrainval_06-nov-2007/VOCdevkit/VOC2007/ImageSets/Main/car_val.txt',dtype=bytes).astype(str)
val_img = val_txt[:,0]
val_label = val_txt[:,1].astype(int)
val_set = ImageDataset(val_img, val_label)
val_dataloader = DataLoader(val_set , batch_size=10, shuffle=False, num_workers=8)

test_txt = np.loadtxt('/content//VOCtest_06-Nov-2007/VOCdevkit/VOC2007/ImageSets/Main/car_test.txt',dtype=bytes).astype(str)
test_img = test_txt[:,0]
test_label = test_txt[:,1].astype(int)
test_set = ImageDataset(test_img, val_label)
test_dataloader = DataLoader(test_set , batch_size=10, shuffle=False, num_workers=8)

import torchvision.models as models
#squeezenet = models.squeezenet1_0()
#densenet = models.densenet161()
#inception = models.inception_v3()
#googlenet = models.googlenet()
#shufflenet = models.shufflenet_v2_x1_0()
#mobilenet = models.mobilenet_v2()
#resnext50_32x4d = models.resnext50_32x4d()
#wide_resnet50_2 = models.wide_resnet50_2()
#mnasnet = models.mnasnet1_0()

import traceback
import matplotlib.pyplot as plt
def visualize_results(val_accuracies):
    print("Saving and showing graph")
    try:
        plt.plot(val_accuracies)
        plt.ylabel('Accuracy')
        plt.savefig('validation_accuracy.png')
        print("Accuracies", val_accuracies)
        # plt.show()
    except Exception as e:
        traceback.print_exc()
        print("Error: Problems generating plot. See if a .png was generated in hw1/. "
              "If not, check the writeup and Piazza hw1p1 thread.")

def train(model, data_loader, test_loader, task='Classification'):
    model.train()

    val_accuracies = []
    for epoch in range(NUM_EPOCHS):
        avg_loss = 0.0
        for batch_num, (feats, labels) in enumerate(data_loader):
            feats, labels = feats.to(device), labels.to(device)
            
            optimizer.zero_grad()
            outputs = model(feats)

            loss = criterion(outputs, labels.long())
            loss.backward()
            optimizer.step()
            
            avg_loss += loss.item()

            if batch_num % 50 == 49:
                print('Epoch: {}\tBatch: {}\tAvg-Loss: {:.4f}'.format(epoch+1, batch_num+1, avg_loss/50))
                avg_loss = 0.0    
            
            torch.cuda.empty_cache()
            del feats
            del labels
            del loss
        
        if task == 'Classification':
            val_loss, val_acc = test_classify(model, test_loader)
            train_loss, train_acc = test_classify(model, data_loader)
            print('Train Loss: {:.4f}\tTrain Accuracy: {:.4f}\tVal Loss: {:.4f}\tVal Accuracy: {:.4f}'.
                  format(train_loss, train_acc, val_loss, val_acc))
            val_accuracies.append(val_acc)
        else:
            test_verify(model, test_loader)
    visualize_results(val_accuracies)


def test_classify(model, test_loader):
    model.eval()
    test_loss = []
    accuracy = 0
    total = 0

    for batch_num, (feats, labels) in enumerate(test_loader):
        feats, labels = feats.to(device), labels.to(device)
        outputs = model(feats)
        
        _, pred_labels = torch.max(F.softmax(outputs, dim=1), 1)
        pred_labels = pred_labels.view(-1)
       
        loss = criterion(outputs, labels.long())
        
        accuracy += torch.sum(torch.eq(pred_labels, labels)).item()
        total += len(labels)
        test_loss.extend([loss.item()]*feats.size()[0])
        del feats
        del labels

    model.train()
    return np.mean(test_loss), accuracy/total


def test_verify(model, test_loader):
    raise NotImplementedError

resnet50 = models.resnet50()
resnet50.fc = nn.Sequential(
    nn.Linear(in_features=2048, out_features=1024, bias=True),
    nn.ReLU(inplace=True),
    nn.Dropout(p=0.5, inplace=False),
    nn.Linear(in_features=1024, out_features=256, bias=True),
    nn.ReLU(inplace=True),
    nn.Dropout(p=0.5, inplace=False),
    nn.Linear(in_features=256, out_features=64, bias=True),
    nn.ReLU(inplace=True),
    nn.Dropout(p=0.5, inplace=False),
    nn.Linear(in_features=64, out_features=3, bias=True),  
)

resnet152 = models.resnet152()
resnet152.fc = nn.Sequential(
    nn.Linear(in_features=2048, out_features=1024, bias=True),
    nn.ReLU(inplace=True),
    nn.Dropout(p=0.5, inplace=False),
    nn.Linear(in_features=1024, out_features=256, bias=True),
    nn.ReLU(inplace=True),
    nn.Dropout(p=0.5, inplace=False),
    nn.Linear(in_features=256, out_features=64, bias=True),
    nn.ReLU(inplace=True),
    nn.Dropout(p=0.5, inplace=False),
    nn.Linear(in_features=64, out_features=3, bias=True),  
)

vgg16 = models.vgg16()
vgg16.classifier = nn.Sequential(
    *list(vgg16.classifier.children())[:-1],
    nn.Linear(in_features=4096, out_features=1024, bias=True),
    nn.ReLU(inplace=True),
    nn.Dropout(p=0.5, inplace=False),
    nn.Linear(in_features=1024, out_features=256, bias=True),
    nn.ReLU(inplace=True),
    nn.Dropout(p=0.5, inplace=False),
    nn.Linear(in_features=256, out_features=64, bias=True),
    nn.ReLU(inplace=True),
    nn.Dropout(p=0.5, inplace=False),
    nn.Linear(in_features=64, out_features=3, bias=True),
)

model = resnet50
model.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=5e-5)

NUM_EPOCHS = 200
train(model, train_dataloader, val_dataloader)

print(resnet50)
print(resnet152)
print(vgg16)